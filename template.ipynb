{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai  # openai==0.27.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".py文件需要指定api_key和api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些官方资料：\n",
    "1. https://platform.openai.com/examples\n",
    "2. https://github.com/openai/openai-cookbook/tree/main/examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最简单的模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大语言模型可以应用于以下场景：\n",
      "\n",
      "1. 机器翻译：大语言模型可以用于改进机器翻译系统，提高翻译质量和流畅度。\n",
      "\n",
      "2. 文本生成：大语言模型可以用于生成文章、新闻、故事等文本内容，可以用于自动写作、创作辅助等领域。\n",
      "\n",
      "3. 问答系统：大语言模型可以用于构建智能问答系统，能够回答用户提出的问题，并提供相关的信息和解决方案。\n",
      "\n",
      "4. 语音识别：大语言模型可以用于提高语音识别系统的准确性和流畅度，使得语音识别结果更加自然和准确。\n",
      "\n",
      "5. 智能助理：大语言模型可以用于构建智能助理，能够理解用户的指令和需求，并提供相应的服务和建议。\n",
      "\n",
      "6. 自动摘要：大语言模型可以用于自动摘要生成，能够从大量文本中提取关键信息，生成简洁准确的摘要。\n",
      "\n",
      "7. 情感分析：大语言模型可以用于情感分析，能够识别文本中的情感倾向，帮助企业了解用户的情感反馈和需求。\n",
      "\n",
      "8. 聊天机器人：大语言模型可以用于构建聊天机器人，能够进行自然语言对话，提供娱乐、咨询、客服等服务。\n",
      "\n",
      "总之，大语言模型在自然语言处理领域有广泛的应用，可以提供自动化、智能化的文本处理和生成能力。\n"
     ]
    }
   ],
   "source": [
    "prompt = '大语言模型有哪些应用场景？'\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提升回答效果的技巧：\n",
    "1. 指定模型身份\n",
    "2. 指定回答格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 金融领域中的大语言模型应用场景有哪些？\n",
      "2. 大语言模型在金融领域中的具体应用案例有哪些？\n",
      "3. 大语言模型在金融领域中的优势和局限性是什么？\n",
      "4. 大语言模型在金融领域中的发展趋势是什么？\n",
      "5. 大语言模型在金融领域中的应用所面临的风险和挑战有哪些？\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "假设你是一名金融专家。\n",
    "请将以下金融相关的问题划分为若干个子问题, 子问题数量不超过5个：\n",
    "\n",
    "格式样例：\n",
    "问题：问题\n",
    "子问题：1.子问题1 2.子问题2 3.子问题3\n",
    "\n",
    "问题：{question}\n",
    "子问题：\n",
    "'''\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt.format(question='大语言模型有哪些应用场景？')}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提升回答效果的技巧：\n",
    "\n",
    "3. 提供示例回答（少样本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.\n",
    "Here are some examples of tweets and their corresponding sentiment labels:\n",
    "\n",
    "Tweet: I love the music\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: I hate the rain\n",
    "Sentiment: Negative\n",
    "\n",
    "Tweet: I'm at the beach\n",
    "Sentiment: Neutral\n",
    "\n",
    "Here is the tweet to be classified:\n",
    "{tweet}\n",
    "'''\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt.format(tweet='\"I loved the new Batman movie!\"')}\n",
    "    ],\n",
    "  temperature=0.0,  # 测评任务需要设置随机性为0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calling：输出结构化数据，适用于信息抽取功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"info\": [\n",
      "        {\n",
      "            \"subject\": \"Black-on-black ware\",\n",
      "            \"predicate\": \"is\",\n",
      "            \"object\": \"pottery tradition\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Black-on-black ware\",\n",
      "            \"predicate\": \"developed by\",\n",
      "            \"object\": \"Puebloan Native American ceramic artists\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Black-on-black ware\",\n",
      "            \"predicate\": \"developed in\",\n",
      "            \"object\": \"Northern New Mexico\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Traditional reduction-fired blackware\",\n",
      "            \"predicate\": \"made by\",\n",
      "            \"object\": \"pueblo artists\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Black-on-black ware\",\n",
      "            \"predicate\": \"produced with\",\n",
      "            \"object\": \"smooth surface\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Black-on-black ware\",\n",
      "            \"predicate\": \"designs applied through\",\n",
      "            \"object\": \"selective burnishing or application of refractory slip\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Another style\",\n",
      "            \"predicate\": \"involves\",\n",
      "            \"object\": \"carving or incising designs and selectively polishing raised areas\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Several families\",\n",
      "            \"predicate\": \"making black-on-black ware\",\n",
      "            \"object\": \"with techniques passed down from matriarch potters\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Artists\",\n",
      "            \"predicate\": \"produced\",\n",
      "            \"object\": \"black-on-black ware\"\n",
      "        },\n",
      "        {\n",
      "            \"subject\": \"Several contemporary artists\",\n",
      "            \"predicate\": \"created works honoring\",\n",
      "            \"object\": \"pottery of their ancestors\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "抽取下面这段话的关系三元组：\n",
    "\n",
    "{context}\n",
    "'''\n",
    "\n",
    "context = '''\n",
    "Black-on-black ware is a 20th- and 21st-century pottery tradition developed by the Puebloan Native American ceramic artists in Northern New Mexico. \n",
    "Traditional reduction-fired blackware has been made for centuries by pueblo artists. \n",
    "Black-on-black ware of the past century is produced with a smooth surface, with the designs applied through selective burnishing or the application of refractory slip. \n",
    "Another style involves carving or incising designs and selectively polishing the raised areas. \n",
    "For generations several families from Kha'po Owingeh and P'ohwhóge Owingeh pueblos have been making black-on-black ware with the techniques passed down from matriarch potters. \n",
    "Artists from other pueblos have also produced black-on-black ware. Several contemporary artists have created works honoring the pottery of their ancestors.\n",
    "'''\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt.format(context=context)}],\n",
    "    functions=[\n",
    "        {\n",
    "            \"name\": \"get_relation_triple\",\n",
    "            \"description\": \"extract relation triple from text\",\n",
    "            \"parameters\": {  # 定义输出json的schema\n",
    "                \"type\": \"object\",  # 最外层必须是object\n",
    "                \"properties\": {  # 定义object的键值对\n",
    "                    \"info\": {  # 定义键的名称\n",
    "                        \"type\": \"array\",  # 定义值的类型\n",
    "                        \"items\": {  # 定义array类型的元素\n",
    "                            \"type\": \"object\",  # array的元素类型是object\n",
    "                            \"properties\": {\n",
    "                                \"subject\": { \n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"subject of triple\"  # 解释每个键的含义\n",
    "                                },\n",
    "                                \"predicate\": { \n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"predicate of triple\"\n",
    "                                },\n",
    "                                \"object\": { \n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"object of triple\"\n",
    "                                },\n",
    "                            },\n",
    "                            'required': ['subject', 'predicate', 'object'],  # 定义必须包含的键\n",
    "                        },\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"info\"],  # 定义必须包含的键\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "\n",
    "print(json.dumps(\n",
    "    json.loads(response.choices[0].message.function_call.arguments), \n",
    "    indent=4, \n",
    "    ensure_ascii=False\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
